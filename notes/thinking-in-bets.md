---
title: Thinking in Bets - by Annie Duke
date: 2023-06-22
permalink: /notes/thinking-in-bets
author_profile: false
tags:
    - notes
---

## *Thinking in Bets* - by Annie Duke

Read: 2023-06-22

Recommend: 10/10

While coaching my 8-year-old son in basketball, I emphasize mastering two-point shots before attempting three-pointers. Previously, I struggled to articulate why this approach was necessary. However, after reading this book, I can now clarify that it's to help him concentrate on honing his skills rather than relying on luck to sink three-point shots. The book underscores the importance of distinguishing skill from luck. Moreover, it reminded me of a technique called 'backcasting' that I used during my high school years. This practice involved visualizing potential challenges for the next day and premeditating possible solutions.


## Notes

**Here are some text that I highlighted in the book:** 

1. The approach of thinking in bets moved me toward objectivity, accuracy, and open-mindedness. That movement compounds over time to create significant changes in our lives.

1. Thinking in bets starts with recognizing that there are exactly two things that determine how our lives turn out: the quality of our decisions and luck. Learning to recognize the difference between the two is what thinking in bets is all about.

1. Pete Carroll was a victim of our tendency to equate the quality of a decision with the quality of its outcome. Poker players have a word for this: “resulting.” 

1. It sounded like a bad result, not a bad decision. The imperfect relationship between results and decision quality devastated the CEO and adversely affected subsequent decisions regarding the company. The CEO had identified the decision as a mistake solely because it didn’t work out. He obviously felt a lot of anguish and regret because of the decision. He stated very clearly that he thought he should have known that the decision to fire the president would turn out badly. His decision-making behavior going forward reflected the belief that he made a mistake. He was not only resulting but also succumbing to its companion, hindsight bias. Hindsight bias is the tendency, after an outcome is known, to see the outcome as having been inevitable. When we say, “I should have known that would happen,” or, “I should have seen it coming,” we are succumbing to hindsight bias.

1. Quick or dead: our brains weren’t built for rationality

1. Game theory was succinctly defined by economist Roger Myerson (one of the game-theory Nobel laureates) as “the study of mathematical models of conflict and cooperation between intelligent rational decision-makers.” Game theory is the modern basis for the study of the bulk of our decision-making, addressing the challenges of changing conditions, hidden information, chance, and multiple people involved in the decisions. 

1. Bronowski quoted von Neumann’s response: “‘No, no,’ he said. ‘Chess is not a game. Chess is a well-defined form of computation. You may not be able to work out the answers, but in theory there must be a solution, a right procedure in any position. Now, real games,’ he said, ‘are not like that at all. Real life is not like that. Real life consists of bluffing, of little tactics of deception, of asking yourself what is the other man going to think I mean to do. And that is what games are about in my theory.’”

1. But life is more like poker. You could make the smartest, most careful decision in firing a company president and still have it blow up in your face. You could run a red light and get through the intersection safely—or follow all the traffic rules and signals and end up in an accident. You could teach someone the rules of poker in five minutes, put them at a table with a world champion player, deal a hand (or several), and the novice could beat the champion. That could never happen in chess. Incomplete information poses a challenge not just for split-second decision-making, but also for learning from past decisions.

1. There are many reasons why wrapping our arms around uncertainty and giving it a big hug will help us become better decision-makers. Here are two of them. First, “I’m not sure” is simply a more accurate representation of the world. Second, and related, when we accept that we can’t be sure, we are less likely to fall into the trap of black-and-white thinking.

1. Decisions are bets on the future, and they aren’t “right” or “wrong” based on whether they turn out well on any particular iteration. An unwanted result doesn’t make our decision wrong if we thought about the alternatives and probabilities in advance and allocated our resources accordingly

1. When we think probabilistically, we are less likely to use adverse results alone as proof that we made a decision error, because we recognize the possibility that the decision might have been good but luck and/or incomplete information (and a sample size of one) intervened.

1. “I wasn’t wrong just because it didn’t turn out well and I shouldn’t change my behavior.” 

1. Redefining wrong allows us to let go of all the anguish that comes from getting a bad result. But it also means we must redefine “right.” If we aren’t wrong just because things didn’t work out, then we aren’t right just because things turned out well.

1. losses in general feel about two times as bad as wins feel good.

1. Our traditional view of betting is very narrow: casinos, sporting events, lottery tickets, wagering against someone else on the chance of a favorable outcome of some event. The definition of “bet” is much broader. Merriam-Webster’s Online Dictionary defines “bet” as “a choice made by thinking about what will probably happen,” “to risk losing (something) when you try to do or achieve something” and “to make decisions that are based on the belief that something will happen or is true.” 

1. In most of our decisions, we are not betting against another person. Rather, we are betting against all the future versions of ourselves that we are not choosing. We are constantly deciding among alternative futures

1. people are credulous creatures who find it very easy to believe and very difficult to doubt.

1. For survival-essential skills, type I errors (false positives) were less costly than type II errors (false negatives). In other words, better to be safe than sorry, especially when considering whether to believe that the rustling in the grass is a lion. We didn’t develop a high degree of skepticism when our beliefs were about things we directly experienced, especially when our lives were at stake.

1. A quick Google search will show that many of our commonly held beliefs are untrue. We just don’t get around to doing Google searches on these things. (Spoiler alerts: (1) Abner Doubleday had nothing to do with inventing the game of baseball. (2) We use all parts of our brain. The 10% figure was made up to sell self-improvement books; neural imaging and brain-injury studies disprove the fabrication. (3) Immigrants didn’t have their names Americanized, involuntarily or otherwise, at Ellis Island.)

1. Whether it is a football game, a protest, or just about anything else, our pre-existing beliefs influence the way we experience the world.

1. If we think of beliefs as only 100% right or 100% wrong, when confronting new information that might contradict our belief, we have only two options: (a) make the massive shift in our opinion of ourselves from 100% right to 100% wrong, or (b) ignore or discredit the new information. It feels bad to be wrong, so we choose (b). Information that disagrees with us is an assault on our self-narrative. We’ll work hard to swat that threat away. On the flip side, when additional information agrees with us, we effortlessly embrace it.

1. We bet on our beliefs. We don’t vet those beliefs well before we form them. We stubbornly refuse to update our beliefs. Now I’ve piled on by telling you that being smart doesn’t help—and can make it worse.

1. Incorporating uncertainty into the way we think about our beliefs comes with many benefits.

1. When we work toward belief calibration, we become less judgmental of ourselves. 

1. The way our lives turn out is the result of two things: the influence of skill and the influence of luck. For the purposes of this discussion, any outcome that is the result of our decision-making is in the skill category.

1. An outcome like losing weight could be the direct result of a change in diet or increased exercise (skill), or a sudden change in our metabolism or a famine (luck). We could get in a car crash because we didn’t stop at a red light (skill) or because another driver ran a red light (luck). A student could do poorly on a test because they didn’t study (skill) or because the teacher is mean (luck). I can lose a hand of poker because I made poor decisions, applying the skill elements of the game poorly, or because the other player got lucky.

1. Outcomes don’t tell us what’s our fault and what isn’t, what we should take credit for and what we shouldn’t. 

1. The way we field outcomes is predictably patterned: we take credit for the good stuff and blame the bad stuff on luck so it won’t be our fault. The result is that we don’t learn from experience well. “Self-serving bias” is the term for this pattern of fielding outcomes. 

1. Self-serving bias has immediate and obvious consequences for our ability to learn from experience.* Blaming the bulk of our bad outcomes on luck means we miss opportunities to examine our decisions to see where we can do better. Taking credit for the good stuff means we will often reinforce decisions that shouldn’t be reinforced and miss opportunities to see where we could have done better. 

1. Where we blame our own bad outcomes on bad luck, when it comes to our peers, bad outcomes are clearly their fault. While our own good outcomes are due to our awesome decision-making, when it comes to other people, good outcomes are because they got lucky. As artist and writer Jean Cocteau said, “We must believe in luck. For how else can we explain the success of those we don’t like?”

1. Steve Bartman had a bad outcome. He reached for the ball, and the Cubs eventually lost. Was that due to his bad decision-making or bad luck? To be sure, he made the decision to reach for the ball, so there was some skill in that. He also, however, had an overwhelming amount of bad luck. Almost uniformly, people discounted that bad luck, blaming Bartman for the loss of that game and the series itself.

1. We are really in competition for resources with everyone. Our genes are competitive. As Richard Dawkins points out, natural selection proceeds by competition among the phenotypes of genes so we literally evolved to compete, a drive that allowed our species to survive. Engaging the world through the lens of competition is deeply embedded in our animal brains. It’s not enough to boost our self-image solely by our own successes. If someone we view as a peer is winning, we feel like we’re losing by comparison. We benchmark ourselves to them. 

1. Not Ivey. For him, the opportunity to learn from his mistakes was much more important than treating that dinner as a self-satisfying celebration. 

1. There are people who, like Phil Ivey, have substituted the routine of truthseeking for the outcome-oriented instinct to focus on seeking credit and avoiding blame. 

1. Just as Duhigg recommends respecting the habit loop, we can also respect that we are built for competition, and that our self-narrative doesn’t exist in a vacuum. Keep the reward of feeling like we are doing well compared to our peers, but change the features by which we compare ourselves: be a better credit-giver than your peers, more willing than others to admit mistakes, more willing to explore possible reasons for an outcome with an open mind, even, and especially, if that might cast you in a bad light or shine a good light on someone else. In this way we can feel that we are doing well by comparison because we are doing something unusual and hard that most people don’t do. That makes us feel exceptional.

1. Thinking in bets triggers a more open-minded exploration of alternative hypotheses, of reasons supporting conclusions opposite to the routine of self-serving bias. 

1. Thinking in bets also triggers perspective taking, leveraging the difference between how we field our own outcomes versus others’ outcomes to get closer to the objective truth. 

1. This makes us more compassionate, both toward ourselves and others. Treating outcome fielding as bets constantly reminds us outcomes are rarely attributable to a single cause and there is almost always uncertainty in figuring out the various causes. Identifying a negative outcome doesn’t have the same personal sting if you turn it into a positive by finding things to learn from it. You don’t have to be on the defensive side of every negative outcome because you can recognize, in addition to things you can improve, things you did well and things outside your control. You realize that not knowing is okay.

1. “Let me give you an example from my own life. . . . For a long time . . . I thought, ‘Geez, people are idiots.’ Then it occurred to me, ‘Is it possible that everybody’s an idiot? Maybe I’m the idiot,’ and it turns out I am.”

1. Letterman’s comment was actually quite perceptive. His mistake was offering up the insight in an inappropriate forum to someone who hadn’t agreed to that kind of truthseeking exchange.

1. I had to resist my urge to moan about my bad luck and focus instead on where I felt I might have made mistakes and where I was confused on what to do in a hand. Because I agreed to the group’s rules of engagement, I had to learn to focus on the things I could control (my own decisions), let go of the things I couldn’t (luck), and work to be able to accurately tell the difference between the two.

1. I learned from this experience that thinking in bets was easier if I had other people to help me. (Even Neo needed help to defeat the machines.) Remember the buddy system from school field trips or camp? Teachers or counselors would pair everybody up with a buddy. Our buddy was supposed to keep us from wandering off or getting into water too deep, and we did the same for our buddy. A good decision group is a grown-up version of the buddy system. 

1. After all, it takes effort to acknowledge and explore our mistakes without feeling bad about ourselves, to forgo credit for a great result, and to realize, with an open mind, that not all our beliefs are true. Truthseeking flies in the face of a lot of comfortable behaviors; it’s hard work and we need breaks to replenish our willpower.

1. Without an explicit charter for exploratory thought and accountability to that charter, our tendency when we interact with others follows our individual tendency, which is toward confirmation. The expression “echo chamber” instantly conjures up the image of what results from our natural drift toward confirmatory thought. 

1. “Complex and open-minded thought is most likely to be activated when decision makers learn prior to forming any opinions that they will be accountable to an audience (a) whose views are unknown, (b) who is interested in accuracy, (c) who is reasonably well-informed, and (d) who has a legitimate reason for inquiring into the reasons behind participants’ judgments/choices.” 

1. Early on in my career, I saw Erik during a break in a tournament, and started moaning to him about my bad luck in losing a big hand. In three sentences, he laid out all the elements of a productive group charter. “I don’t want to hear it. I’m not trying to hurt your feelings, but if you have a question about a hand, you can ask me about strategy all day long. I just don’t think there’s much purpose in a poker story if the point is about something you had no control over, like bad luck.”

1. Accountability, like reinforcement of accuracy, also improves our decision-making and information processing when we are away from the group because we know in advance that we will have to answer to the group for our decisions. 

1. Dissent channels and red teams are a beautiful implementation of Mill’s bedrock principle that we can’t know the truth of a matter without hearing the other side. This commitment to diversity of opinion is something that we would be wise to apply to our own decision groups. 

1. This polarization warns against forming a decision group that is a collection of clones who share the same opinions and knowledge sources we do. The more homogeneous we get, the more the group will promote and amplify confirmatory thought. Sadly, that’s exactly what we drift toward. Even Supreme Court justices do that. We are all familiar with this tendency in politics; it’s the complaint on both sides of the political aisle. Conservatives complain that liberals live in an echo chamber where they just repeat and confirm their point of view. They aren’t open to new information or ideas that don’t fit what they already believe. That’s the exact same criticism liberals have of conservatives.

1. As the authors of the BBS paper recognized, “Even research communities of highly intelligent and well-meaning individuals can fall prey to confirmation bias, as IQ is positively correlated with the number of reasons people find to support their own side in an argument.” That’s how robust these biases are. We see that even judges and scientists succumb to these biases. We shouldn’t feel bad, whatever our situation, about admitting that we also need help.

1. Experimental studies cited in the BBS paper found that confirmation bias led reviewers “to work extra hard to find flaws with papers whose conclusions they dislike, and to be more permissive about methodological issues when they endorse the conclusions.”

1. The BBS paper, and the continuing work of Heterodox Academy, includes specific recommendations geared toward encouraging diversity and dissenting opinions. I encourage you to read the specific recommendations, which include things like a stated antidiscrimination policy (against opposing viewpoints), developing ways to encourage people with contrary viewpoints to join the group and engage in the process, and surveying to gauge the actual heterogeneity or homogeneity of opinion in the group. These are exactly the kinds of things we would do well to adopt (and, where necessary, adapt) for groups in our personal lives and in the workplace.

1. Accuracy, accountability, and diversity wrapped into a group’s charter all contribute to better decision-making, especially if the group promotes thinking in bets. 

1. Even without conflicting versions, the Rashomon Effect reminds us that we can’t assume one version of a story is accurate or complete. We can’t count on someone else to provide the other side of the story, or any individual’s version to provide a full and objective accounting of all the relevant information. That’s why, within a decision group, it is helpful to commit to this Mertonian norm on both sides of the discussion. When presenting a decision for discussion, we should be mindful of details we might be omitting and be extra-safe by adding anything that could possibly be relevant. On the evaluation side, we must query each other to extract those details when necessary.

1. We are naturally reluctant to share information that could encourage others to find fault in our decision-making. My group made this easier by making me feel good about committing myself to improvement. When I shared details that cast me in what I perceived to be a bad light, I got a positive self-image update from the approval of players I respected. In my consulting, I’ve encouraged companies to make sure they don’t define “winning” solely by results or providing a self-enhancing narrative.

1. Whether the situation involves facts, ideas, beliefs, opinions, or predictions, the substance of the information has merit (or lack of merit) separate from where it came from. 

1. Another way to disentangle the message from the messenger is to imagine the message coming from a source we value much more or much less. If we hear an account from someone we like, imagine if someone we didn’t like told us the same story, and vice versa. This can be incorporated into an exploratory group’s work, asking each other, “How would we feel about this if we heard it from a much different source?” We can take this process of vetting information in the group further, initially and intentionally omitting where or whom we heard the idea from.

1. If the group is blind to the outcome, it produces higher fidelity evaluation of decision quality. The best way to do this is to deconstruct decisions before an outcome is known. 

1. Skepticism gets a bum rap because it tends to be associated with negative character traits. Someone who disagrees could be considered “disagreeable.” Someone who dissents may be creating “dissention.” Maybe part of it is that “skeptical” sounds like “cynical.” Yet true skepticism is consistent with good manners, civil discourse, and friendly communications. Skepticism is about approaching the world by asking why things might not be true rather than why they are true. It’s a recognition that, while there is an objective truth, everything we believe about the world is not true. Thinking in bets embodies skepticism by encouraging us to examine what we do and don’t know and what our level of confidence is in our beliefs and predictions. This moves us closer to what is objectively true.

1. Less formally, look for opportunities to recruit a devil’s advocate on an ad hoc basis. When seeking advice, we can ask specific questions to encourage the other person to figure out reasons why we might be wrong.

1. We can think of this broadly as an attempt to avoid the language of “no.” In the performance art of improvisation, the first advice is that when someone starts a scene, you should respond with “yes, and . . .” “Yes” means you are accepting the construct of the situation. “And” means you are adding to it. That’s an excellent guideline in any situation in which you want to encourage exploratory thought. The important thing is to try to find areas of agreement to maintain the spirit of partnership in seeking the truth. In expressing potentially contradictory or dissenting information, our language ideally minimizes the element of disagreement.

1.  If someone is off-loading emotion to us, we can ask them if they are just looking to vent or if they are looking for advice. If they aren’t looking for advice, that’s fine. The rules of engagement have been made clear. Sometimes, people just want to vent. I certainly do. It’s in our nature. 

1. This is a good approach to communicating with our children, who, with their developing egos, don’t necessarily need a red pill shoved down their throats. A child isn’t equipped to consent to the challenges of truthseeking exchanges. 

1. My son was expert at fielding bad test scores as the teacher’s fault. I had to be careful not to Letterman him. Instead, I would tell him, “It must be hard to have a teacher like that. Do you think there’s anything you can do to improve your grade in the future?” 

1. Just as we can recruit other people to be our decision buddies, we can recruit other versions of ourselves to act as our own decision buddies. We can harness the power of mental time traveling, operationalizing it, encouraging it, and figuring out ways to cause that collision of past, present, and future as much as possible. Present-us needs that help, and past-us and future-us can be the best decision buddies for the job.

1. The best poker players develop practical ways to incorporate their long-term strategic goals into their in-the-moment decisions. 

1. Improving decision quality is about increasing our chances of good outcomes, not guaranteeing them. 

1. Jerry Seinfeld, on why he doesn’t get enough sleep: “I stay up late at night because I’m Night Guy. Night Guy wants to stay up late. ‘What about getting up after five hours of sleep?’ ‘That’s Morning Guy’s problem. That’s not my problem. I’m Night Guy. I stay up as late as I want.’ So you get up in the morning: you’re exhausted, you’re groggy. ‘Oooh, I hate that Night Guy.’ See, Night Guy always screws Morning Guy.” That’s a good example of how we struggle in the present to take care of our future-self. Night Jerry is always going to want to stay up late and, if Morning Jerry has no say in the decision, Night Jerry will get his way regardless of what’s in Jerry’s longer-term best interest. When we make in-the-moment decisions (and don’t ponder the past or future), we are more likely to be irrational and impulsive.

1. This tendency we all have to favor our present-self at the expense of our future-self is called temporal discounting. We are willing to take an irrationally large discount to get a reward now instead of waiting for a bigger reward later. 

1. Wouldn’t it be great if Morning Jerry could travel back in time and tap Night Jerry on the shoulder to tell him to go to bed? As it turns out, there’s an app for that.

1. Bringing our future-self into the decision gets us started thinking about the future consequences of those in-the-moment decisions. Fundamentally, Morning Jerry and Night Jerry are living the same life, and getting Morning Jerry into Night Jerry’s face will remind him of that. Seeing our aged-self in the mirror, along with a spreadsheet showing us how future-us has to struggle to get by, is a persuasive reminder to put aside some discretionary spending money for retirement. It’s that tap on the shoulder from our future-self. “Hey, don’t forget about me. I’m going to exist and I’d like you to please take that into account.”

1. Nietzsche said that remorse was “adding to the first act of stupidity a second.” Thoreau, on the other hand, praised the power of regret: “Make the most of your regrets; never smother your sorrow, but tend and cherish it till it comes to have a separate and integral interest. To regret deeply is to live afresh.”

1. But if regret occurred before a decision instead of after, the experience of regret might get us to change a choice likely to result in a bad outcome.

1. That was one of the purposes of my loss limit in poker. Because of the loss-limit agreement I had made with myself and my group, I ran the conversation in my head that I’d be forced to have when I explained why I kept playing beyond my limit. It gave me a chance to regret the decision before I bought more chips.

1. One of our time-travel goals is to create moments like that, where we can interrupt an in-the-moment decision and take some time to consider the decision from the perspective of our past and future. We can then create a habit routine around these decision interrupts to encourage this perspective taking, asking ourselves a set of simple questions at the moment of the decision designed to get future-us and past-us involved. We can do this by imagining how future-us is likely to feel about the decision or by imagining how we might feel about the decision today if past-us had made it. 

1. Business journalist and author Suzy Welch developed a popular tool known as 10-10-10 that has the effect of bringing future-us into more of our in-the-moment decisions. “Every 10-10-10 process starts with a question. . . . [W]hat are the consequences of each of my options in ten minutes? In ten months? In ten years?” This set of questions triggers mental time travel that cues that accountability conversation (also encouraged by a truthseeking decision group). We can build on Welch’s tool by asking the questions through the frame of the past: “How would I feel today if I had made this decision ten minutes ago? Ten months ago? Ten years ago?” Whichever frame we choose, we draw on our past experiences (including similar decisions we may have regretted) in answering the questions, recruiting into the decision those less-reactive brain pathways that control executive functioning.

1. Moving regret in front of a decision has numerous benefits. First, obviously, it can influence us to make a better decision. Second, it helps us treat ourselves (regardless of the actual decision) more compassionately after the fact. 

1. After-the-fact regret can consume us. Like all emotions, regret initially feels intense but gets better with time. Time-travel strategies can help us remember that the intensity of what we feel now will subside over time. And that helps reduce the emotion we feel in the moment, making it less likely that we will prove Nietzsche right and add a second act of stupidity to the first.

1. Our problem is that we’re ticker watchers of our own lives. Happiness (however we individually define it) is not best measured by looking at the ticker, zooming in and magnifying moment-by-moment or day-by-day movements. We would be better off thinking about our happiness as a long-term stock holding. We would do well to view our happiness through a wide-angle lens, striving for a long, sustaining upward trend in our happiness stock, so it resembles the first Berkshire Hathaway chart.

1. The way we field outcomes is path dependent. It doesn’t so much matter where we end up as how we got there. What has happened in the recent past drives our emotional response much more than how we are doing overall. That’s how we can win $100 and be sad, and lose $100 and be happy. The zoom lens doesn’t just magnify, it distorts.

1. their jargon has a variety of terms for the concept that “bad outcomes can have an impact on your emotions that compromise your decision-making going forward so that you make emotionally charged, irrational decisions that are likely to result in more bad outcomes that will then negatively impact your decision-making going forward and so on.” The most common is tilt. Tilt is the poker player’s worst enemy, and the word instantly communicates to other poker players that you were emotionally unhinged in your decision-making because of the way things turned out. If you blow some recent event out of proportion and react in a drastic way, you’re on tilt.

1. When the emotional center of the brain starts pinging, the limbic system (specifically the amygdala) shuts down the prefrontal cortex. We light up . . . then we shut down our cognitive control center.

1. By recognizing in advance these verbal and physiological signs that ticker watching is making us tilt, we can commit to develop certain habit routines at those moments. We can precommit to walk away from the situation when we feel the signs of tilt, whether it’s a fight with a spouse or child, aggravation in a work situation, or losing at a poker table. We can take some space till we calm down and get some perspective, recognizing that when we are on tilt we aren’t decision fit. Aphorisms like “take ten deep breaths” and “why don’t you sleep on it?” capture this desire to avoid decisions while on tilt.

1. At the very beginning of my poker career, I heard an aphorism from some of the legends of the profession: “It’s all just one long poker game.” That aphorism is a reminder to take the long view, especially when something big happened in the last half hour, or the previous hand—or when we get a flat tire. Once we learn specific ways to recruit past and future versions of us to remind ourselves of this, we can keep the most recent upticks and downticks in their proper perspective. When we take the long view, we’re going to think in a more rational way.

1. The plan worked perfectly. This action—past-us preventing present-us from doing something stupid—has become known as a Ulysses contract. 

1. It’s the perfect interaction between past-you, present-you, and future-you. Ulysses recognized that his future-self (along with his crew) would become entranced by the Sirens and steer toward the rocks. So he had his crew fill their ears with wax and tie his hands to the mast, literally binding his future-self to better behavior. One of the simplest examples of this kind of contract is using a ride-sharing service when you go to a bar. A past version of you, who anticipated that you might decide irrationally about whether you are okay to drive, has bound your hands by taking the car keys out of them.

1. When you are physically prohibited from deciding, you are interrupted in the sense that you are prevented from acting on an irrational impulse; the option simply isn’t there. That’s the brute-force way to do this kind of time traveling. Past-Ulysses interrupted present-Ulysses’s decision by taking the decision, literally, out of his hands.

1. The precommitments, however, provide a stop-and-think moment before acting, triggering the potential for deliberative thought. 

1. [DON'T] Expressions that explicitly signal motivated reasoning, accepting or rejecting information without much evidence, like “conventional wisdom” or “if you ask anybody” or “Can you prove that it’s not true?” Similarly, look for expressions that you’re participating in an echo chamber, like “everyone agrees with me.”

1. [DON'T] Lack of self-compassion: if we’re going to be self-critical, the focus should be on the lesson and how to calibrate future decisions. “I have the worst judgment on relationships” or “I should have known” or “How could I be so stupid?”

1. “When faced with highly uncertain conditions, military units and major corporations sometimes use an exercise called scenario planning. The idea is to consider a broad range of possibilities for how the future might unfold to help guide long-term planning and preparation.”

1. This kind of scenario planning is a form of mental time travel we can do on our own.

1. Backcasting: working backward from a positive future

1. You know that Chinese proverb, “A journey of a thousand miles starts with a single step”? Turns out, if we were contemplating a thousand-mile walk, we’d be better off imagining ourselves looking back from the destination and figuring how we got there. 

1. They “found that prospective hindsight—imagining that an event has already occurred—increases the ability to correctly identify reasons for future outcomes by 30%.”

1. The most common form of working backward from our goal to map out the future is known as backcasting. In backcasting, we imagine we’ve already achieved a positive outcome, holding up a newspaper with the headline “We Achieved Our Goal!” Then we think about how we got there.

1. Premortems: working backward from a negative future

1. A premortem is an investigation into something awful, but before it happens. We all like to bask in an optimistic view of the future. We generally are biased to overestimate the probability of good things happening. Looking at the world through rose-colored glasses is natural and feels good, but a little naysaying goes a long way. A premortem is where we check our positive attitude at the door and imagine not achieving our goals.

1. Despite the popular wisdom that we achieve success through positive visualization, it turns out that incorporating negative visualization makes us more likely to achieve our goals. Gabriele Oettingen, professor of psychology at NYU and author of Rethinking Positive Thinking: Inside the New Science of Motivation, has conducted over twenty years of research, consistently finding that people who imagine obstacles in the way of reaching their goals are more likely to achieve success, a process she has called “mental contrasting.” 

1. We make better decisions, and we feel better about those decisions, once we get our past-, present-, and future-selves to hang out together.

1. It may not feel so good during the planning process to include this focus on the negative space. Over the long run, however, seeing the world more objectively and making better decisions will feel better than turning a blind eye to negative scenarios.

1. That’s what hindsight bias is, and we’re all running amok through the forest with a chainsaw once we get an outcome. Once something occurs, we no longer think of it as probabilistic—or as ever having been probabilistic. This is how we get into the frame of mind where we say, “I should have known” or “I told you so.” This is where unproductive regret comes from.

1. By keeping an accurate representation of what could have happened (and not a version edited by hindsight), memorializing the scenario plans and decision trees we create through good planning process, we can be better calibrators going forward. 

1. To some degree, we’re all outcome junkies, but the more we wean ourselves from that addiction, the happier we’ll be. None of us is guaranteed a favorable outcome, and we’re all going to experience plenty of unfavorable ones. We can always, however, make a good bet. And even when we make a bad bet, we usually get a second chance because we can learn from the experience and make a better bet the next time.

1. She has also been incredibly generous in the time since she was my advisor, especially given that I left the program before getting my PhD. She was happy for the life I created after leaving and never once made me feel bad for not finishing.

